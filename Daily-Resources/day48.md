# Day 48 

Today I dove into the actual math and statistics behind regularization, which was weridly more complicated than I expected. It is always funny when I discover something that I have used hundreds if not thousands of times is actually has a lot more complex than I would of assumed.

Resources: 

Elastic-Net (Sklearn)
https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html

Ridge (Sklearn)
https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html

Intuitions on L1 and L2 Regularisation
https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261

Regularization Part 1 by Statquest
https://www.youtube.com/watch?v=Q81RR3yKn30&t=622s

L10.4 L2 Regularization for Neural Nets
https://www.youtube.com/watch?v=uu2X47cSLmM

Ridge Regression (PSU)
https://online.stat.psu.edu/stat857/node/155/

Bias Variance Trade-Off by Prof. Ryan Ahmed
https://www.youtube.com/watch?v=1JWpXHgqj54
